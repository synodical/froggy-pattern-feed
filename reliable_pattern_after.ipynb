{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>fave_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Crocheturlay</td>\n",
       "      <td>720780</td>\n",
       "      <td>2017/02/19 15:08:49 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cozykrisknits</td>\n",
       "      <td>393166</td>\n",
       "      <td>2014/12/25 14:31:01 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cozykrisknits</td>\n",
       "      <td>447781</td>\n",
       "      <td>2014/12/25 14:29:06 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cozykrisknits</td>\n",
       "      <td>117296</td>\n",
       "      <td>2013/01/07 22:42:44 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cozykrisknits</td>\n",
       "      <td>224811</td>\n",
       "      <td>2013/01/07 22:39:07 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756709</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>173758</td>\n",
       "      <td>2013/03/28 16:34:16 -0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756710</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>195006</td>\n",
       "      <td>2013/03/28 16:34:07 -0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756711</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>143595</td>\n",
       "      <td>2013/03/28 16:34:02 -0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756712</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>181436</td>\n",
       "      <td>2013/03/28 16:33:52 -0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756713</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>184008</td>\n",
       "      <td>2013/03/28 16:33:47 -0400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3756714 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id  pattern_id                  fave_date\n",
       "0         Crocheturlay      720780  2017/02/19 15:08:49 -0500\n",
       "1        cozykrisknits      393166  2014/12/25 14:31:01 -0500\n",
       "2        cozykrisknits      447781  2014/12/25 14:29:06 -0500\n",
       "3        cozykrisknits      117296  2013/01/07 22:42:44 -0500\n",
       "4        cozykrisknits      224811  2013/01/07 22:39:07 -0500\n",
       "...                ...         ...                        ...\n",
       "3756709       alchemia      173758  2013/03/28 16:34:16 -0400\n",
       "3756710       alchemia      195006  2013/03/28 16:34:07 -0400\n",
       "3756711       alchemia      143595  2013/03/28 16:34:02 -0400\n",
       "3756712       alchemia      181436  2013/03/28 16:33:52 -0400\n",
       "3756713       alchemia      184008  2013/03/28 16:33:47 -0400\n",
       "\n",
       "[3756714 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"./user_data.csv\", encoding='cp949')\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             fave_date\n",
      "user_id          pattern_id           \n",
      "A-Bear           5708                2\n",
      "                 13085               2\n",
      "A-Ko-Cloudartowl 165798              2\n",
      "                 188720              2\n",
      "                 293756              2\n",
      "...                                ...\n",
      "curlyredheadgirl 159043              2\n",
      "                 487111              2\n",
      "cushing          48126               2\n",
      "cute2go          395263              2\n",
      "cutevira         725964              2\n",
      "\n",
      "[17751 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 좋아요 두개 이상 누른 사용자 \n",
    "much_liker = ratings.groupby(['user_id', 'pattern_id']).count() \n",
    "bool_liker = much_liker['fave_date'] > 1\n",
    "much_liker = much_liker[bool_liker]\n",
    "print(much_liker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  pattern_id                  fave_date\n",
      "3547964  A-Bear        5708  2009/03/05 22:02:47 -0500\n",
      "3547966  A-Bear        5708  2009/03/05 22:00:56 -0500\n"
     ]
    }
   ],
   "source": [
    "# 정말 이런식으로 A-Bear처럼 두개씩 누른 사람들이 있다\n",
    "user = ratings['user_id'] == 'A-Bear' \n",
    "pat = ratings['pattern_id'] == 5708\n",
    "\n",
    "print(ratings[pat & user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 제거\n",
    "ratings = ratings.drop_duplicates(['user_id', 'pattern_id'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id  pattern_id                  fave_date\n",
      "3547966  A-Bear        5708  2009/03/05 22:00:56 -0500\n"
     ]
    }
   ],
   "source": [
    "# A-Bear가 5708을 누른 데이터도 이제 한개뿐\n",
    "user = ratings['user_id'] == 'A-Bear' \n",
    "pat = ratings['pattern_id'] == 5708\n",
    "print(ratings[pat & user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "A-Bear               291\n",
      "A-Jar-Of-Bees         23\n",
      "A-KN                 615\n",
      "A-Kelli               65\n",
      "A-Ko-Cloudartowl    3686\n",
      "                    ... \n",
      "cvilleknits           38\n",
      "cvitt                 24\n",
      "cvivianay             44\n",
      "cvjunebug            207\n",
      "cvkasdan              16\n",
      "Name: user_id, Length: 17636, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "users = ratings.groupby('user_id')['user_id'].count()\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern_id\n",
      "10        157\n",
      "13         27\n",
      "16        171\n",
      "17        305\n",
      "20        123\n",
      "         ... \n",
      "774662      1\n",
      "774666      1\n",
      "774667      1\n",
      "774670      1\n",
      "774676      1\n",
      "Name: pattern_id, Length: 410633, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "patterns = ratings.groupby('pattern_id')['pattern_id'].count()\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  count\n",
      "user_id                \n",
      "A-Bear              291\n",
      "A-KN                615\n",
      "A-Ko-Cloudartowl   3686\n",
      "A-L                 192\n",
      "A2Knitzi            280\n",
      "...                 ...\n",
      "cutiepie3000        150\n",
      "cutiepiemommy       107\n",
      "cutikula            226\n",
      "cutloose            458\n",
      "cvjunebug           207\n",
      "\n",
      "[5630 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 신뢰할만한 user를 걸러내자.\n",
    "# 어떤 user가 평가한 패턴의 개수가 N개 이상이라면, 이 user는 여러 개의 패턴을 보고 평가한 것으로 볼 수 있다.\n",
    "# 그러므로 이 사용자의 평가는 믿을만하다고 가정한다.\n",
    "N = 100\n",
    "reliable_users = users[users > N]\n",
    "reliable_users = reliable_users.to_frame()\n",
    "# index와, 첫번째 column의 이름이 user_id라 pd.merge 연산이 불가하므로 column name 치환\n",
    "reliable_users.rename(columns={'user_id':'count'}, inplace=True)\n",
    "print(reliable_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 거른 믿을만한 사용자 집단과 rating set의 교집합을 걸러내어,\n",
    "# 믿을만한 사용자 집단이 평가하지 않은 pattern id는 dataset에서 제외한다.\n",
    "merge_ratings = pd.merge(ratings, reliable_users, on=['user_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>fave_date</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bibicoco</td>\n",
       "      <td>193187</td>\n",
       "      <td>2017/04/29 07:32:06 -0400</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bibicoco</td>\n",
       "      <td>277368</td>\n",
       "      <td>2017/04/02 00:48:07 -0400</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bibicoco</td>\n",
       "      <td>241913</td>\n",
       "      <td>2016/04/23 23:55:12 -0400</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bibicoco</td>\n",
       "      <td>368955</td>\n",
       "      <td>2015/10/12 21:39:27 -0400</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bibicoco</td>\n",
       "      <td>547501</td>\n",
       "      <td>2015/10/12 21:35:50 -0400</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465470</th>\n",
       "      <td>asmaloy</td>\n",
       "      <td>186328</td>\n",
       "      <td>2011/01/07 07:09:58 -0500</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465471</th>\n",
       "      <td>asmaloy</td>\n",
       "      <td>40292</td>\n",
       "      <td>2011/01/07 06:43:35 -0500</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465472</th>\n",
       "      <td>asmaloy</td>\n",
       "      <td>146846</td>\n",
       "      <td>2011/01/05 07:29:34 -0500</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465473</th>\n",
       "      <td>asmaloy</td>\n",
       "      <td>215288</td>\n",
       "      <td>2011/01/01 13:38:16 -0500</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465474</th>\n",
       "      <td>asmaloy</td>\n",
       "      <td>219580</td>\n",
       "      <td>2010/12/31 06:39:29 -0500</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3465475 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  pattern_id                  fave_date  count\n",
       "0        Bibicoco      193187  2017/04/29 07:32:06 -0400    111\n",
       "1        Bibicoco      277368  2017/04/02 00:48:07 -0400    111\n",
       "2        Bibicoco      241913  2016/04/23 23:55:12 -0400    111\n",
       "3        Bibicoco      368955  2015/10/12 21:39:27 -0400    111\n",
       "4        Bibicoco      547501  2015/10/12 21:35:50 -0400    111\n",
       "...           ...         ...                        ...    ...\n",
       "3465470   asmaloy      186328  2011/01/07 07:09:58 -0500    128\n",
       "3465471   asmaloy       40292  2011/01/07 06:43:35 -0500    128\n",
       "3465472   asmaloy      146846  2011/01/05 07:29:34 -0500    128\n",
       "3465473   asmaloy      215288  2011/01/01 13:38:16 -0500    128\n",
       "3465474   asmaloy      219580  2010/12/31 06:39:29 -0500    128\n",
       "\n",
       "[3465475 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "A-Bear               291\n",
      "A-KN                 615\n",
      "A-Ko-Cloudartowl    3686\n",
      "A-L                  192\n",
      "A2Knitzi             280\n",
      "                    ... \n",
      "cutiepie3000         150\n",
      "cutiepiemommy        107\n",
      "cutikula             226\n",
      "cutloose             458\n",
      "cvjunebug            207\n",
      "Name: user_id, Length: 5630, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 교집합 연산이 잘 되었는지 확인을 위한 작업\n",
    "# 교집합 연산 전 reliable users 의 row 길이와, \n",
    "# 현재 merge된 ratings에서 user id끼리 groupby한 연산의 결과가 같으므로, \n",
    "# 이는 옳게 교집합 연산이 되었다\n",
    "users = merge_ratings.groupby('user_id')['user_id'].count()\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern_id\n",
      "10        143\n",
      "13         25\n",
      "16        148\n",
      "17        283\n",
      "20        109\n",
      "         ... \n",
      "774662      1\n",
      "774666      1\n",
      "774667      1\n",
      "774670      1\n",
      "774676      1\n",
      "Name: pattern_id, Length: 402052, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "patterns = merge_ratings.groupby('pattern_id')['pattern_id'].count()\n",
    "print(patterns)\n",
    "# 그러나, 사람마다 취향이 너무 달라서 제외된 패턴임에도 row가 410000개이다. 여전히 너무 많아 MF를 실행할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count\n",
      "pattern_id       \n",
      "10            143\n",
      "16            148\n",
      "17            283\n",
      "20            109\n",
      "29            584\n",
      "...           ...\n",
      "761594        116\n",
      "763023        115\n",
      "763263        112\n",
      "763264        130\n",
      "766149        106\n",
      "\n",
      "[3859 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 이젠 신뢰할만한 pattern을 걸러내자.\n",
    "# 어떤 pattern이 평가된 횟수가 M개 이상이라면, 이 패턴은 많은 사용자에게 평가받았다.\n",
    "# 그러므로 이 패턴은 보편적 취향에 부합하며, 다른 이에게도 추천할만하다.\n",
    "M = 100\n",
    "reliable_patterns = patterns[patterns > M]\n",
    "reliable_patterns = reliable_patterns.to_frame()\n",
    "reliable_patterns.rename(columns={'pattern_id':'count'}, inplace=True)\n",
    "print(reliable_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 거른 믿을만한 사용자 집단과 rating set의 교집합을 걸러내어,\n",
    "# 믿을만한 사용자 집단이 평가하지 않은 pattern id는 dataset에서 제외한다.\n",
    "s_merge_ratings = pd.merge(merge_ratings, reliable_patterns, on=['pattern_id'], how='inner')\n",
    "# s_merge_ratings = s_merge_ratings.drop(columns = ['fave_date','count_x', 'count_y'])\n",
    "s_merge_ratings = s_merge_ratings.drop(columns = ['count_x', 'count_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "A-Bear               67\n",
      "A-KN                 98\n",
      "A-Ko-Cloudartowl    450\n",
      "A-L                  75\n",
      "A2Knitzi             86\n",
      "                   ... \n",
      "cutiepie3000          6\n",
      "cutiepiemommy         9\n",
      "cutikula             41\n",
      "cutloose             59\n",
      "cvjunebug            10\n",
      "Name: user_id, Length: 5622, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# user는 줄지 않았다\n",
    "users = s_merge_ratings.groupby('user_id')['user_id'].count()\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern_id\n",
      "10        143\n",
      "16        148\n",
      "17        283\n",
      "20        109\n",
      "29        584\n",
      "         ... \n",
      "761594    116\n",
      "763023    115\n",
      "763263    112\n",
      "763264    130\n",
      "766149    106\n",
      "Name: pattern_id, Length: 3859, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 교집합 연산이 잘 되었는지 확인을 위한 작업\n",
    "# 교집합 연산 전 reliable patterns 의 row 길이와, \n",
    "# 현재 merge된 ratings에서 pattern id끼리 groupby한 연산의 결과가 같으므로, \n",
    "# 이는 옳게 교집합 연산이 되었다\n",
    "patterns = s_merge_ratings.groupby('pattern_id')['pattern_id'].count()\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 user_id  pattern_id                  fave_date\n",
      "0               Bibicoco      277368  2017/04/02 00:48:07 -0400\n",
      "1         churncreeklady      277368  2014/05/15 13:10:56 -0400\n",
      "2           anneliesbaes      277368  2014/08/15 04:08:53 -0400\n",
      "3       ConstanceTricote      277368  2012/10/28 11:30:45 -0400\n",
      "4                 Ann357      277368  2015/07/22 16:00:25 -0400\n",
      "...                  ...         ...                        ...\n",
      "732657         Brewst502      164869  2010/11/25 18:06:12 -0500\n",
      "732658   charliehrtsmatt      164869  2012/05/01 23:47:49 -0400\n",
      "732659        ArgyleLove      164869  2016/07/17 17:21:11 -0400\n",
      "732660        badpallone      164869  2010/10/11 09:18:01 -0400\n",
      "732661            aerynn      164869  2011/01/22 22:39:15 -0500\n",
      "\n",
      "[732662 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(s_merge_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007/09/27 10:10:22 -0400 2017/09/16 05:22:01 -0400\n"
     ]
    }
   ],
   "source": [
    "# print(min(s_merge_ratings['fave_date']), max(s_merge_ratings['fave_date']))\n",
    "\n",
    "# s_merge_ratings['fave_date'] = pd.to_datetime(s_merge_ratings['fave_date'])\n",
    "print(min(s_merge_ratings['fave_date']), max(s_merge_ratings['fave_date']))\n",
    "\n",
    "s_merge_ratings.loc[s_merge_ratings['fave_date'] <= '2017/12/31', 'score'] = 5\n",
    "s_merge_ratings.loc[s_merge_ratings['fave_date'] <= '2015/12/31', 'score'] = 4\n",
    "s_merge_ratings.loc[s_merge_ratings['fave_date'] <= '2013/12/31', 'score'] = 3\n",
    "s_merge_ratings.loc[s_merge_ratings['fave_date'] <= '2011/12/31', 'score'] = 2\n",
    "s_merge_ratings.loc[s_merge_ratings['fave_date'] <= '2009/12/31', 'score'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_merge_ratings = s_merge_ratings.drop(columns = ['fave_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  score                                                   \\\n",
      "pattern_id       10     16     17     20     29     38     40     45       \n",
      "user_id                                                                    \n",
      "A-Bear              NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "A-KN                NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "A-Ko-Cloudartowl    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "A-L                 NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "A2Knitzi            NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "...                 ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "cutiepie3000        NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "cutiepiemommy       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "cutikula            NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "cutloose            NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "cvjunebug           NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "                                ...                                            \\\n",
      "pattern_id       54     58      ... 754478 757448 758675 760169 760196 761594   \n",
      "user_id                         ...                                             \n",
      "A-Bear              NaN    1.0  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "A-KN                NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "A-Ko-Cloudartowl    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "A-L                 NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "A2Knitzi            NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "...                 ...    ...  ...    ...    ...    ...    ...    ...    ...   \n",
      "cutiepie3000        NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "cutiepiemommy       NaN    NaN  ...    NaN    NaN    5.0    NaN    NaN    NaN   \n",
      "cutikula            NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "cutloose            NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "cvjunebug           NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "                                              \n",
      "pattern_id       763023 763263 763264 766149  \n",
      "user_id                                       \n",
      "A-Bear              NaN    NaN    NaN    NaN  \n",
      "A-KN                NaN    NaN    NaN    NaN  \n",
      "A-Ko-Cloudartowl    NaN    NaN    NaN    NaN  \n",
      "A-L                 NaN    NaN    NaN    NaN  \n",
      "A2Knitzi            NaN    NaN    NaN    NaN  \n",
      "...                 ...    ...    ...    ...  \n",
      "cutiepie3000        NaN    NaN    NaN    NaN  \n",
      "cutiepiemommy       NaN    NaN    NaN    NaN  \n",
      "cutikula            NaN    NaN    NaN    NaN  \n",
      "cutloose            NaN    NaN    NaN    NaN  \n",
      "cvjunebug           NaN    NaN    NaN    NaN  \n",
      "\n",
      "[5622 rows x 3859 columns]\n"
     ]
    }
   ],
   "source": [
    "# s_merge_ratings['values'] = 1\n",
    "\n",
    "s_merge_ratings = s_merge_ratings.pivot( index='user_id', columns='pattern_id')\n",
    "forcopy = pd.DataFrame(s_merge_ratings)\n",
    "print(s_merge_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b0e5420a252d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms_merge_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_merge_ratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ms_merge_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_merge_ratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ms_merge_ratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./sgd.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_merge_ratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "s_merge_ratings = s_merge_ratings.fillna(0)\n",
    "s_merge_ratings = s_merge_ratings.to_numpy()\n",
    "s_merge_ratings.to_csv(\"./sgd.csv\")\n",
    "print(s_merge_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    " \n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "    error = 0\n",
    "    # 두개의 분해된 행렬 P와 Q.T의 내적 곱으로 예측 R 행렬 생성\n",
    "    full_pred_matrix = np.dot(P, Q.T)\n",
    "     \n",
    "    # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출하여 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
    "     \n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "       \n",
    "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "     \n",
    "    return rmse\n",
    " \n",
    " \n",
    "def matrix_factorization(R, K, steps=200, learning_rate=0.01, r_lambda = 0.01):\n",
    "    num_users, num_items = R.shape\n",
    "    # P와 Q 매트릭스의 크기를 지정하고 정규분포를 가진 랜덤한 값으로 입력합니다.\n",
    "    np.random.seed(1)\n",
    "    P = np.random.normal(scale=1./K, size=(num_users, K))\n",
    "    Q = np.random.normal(scale=1./K, size=(num_items, K))\n",
    " \n",
    "    break_count = 0\n",
    "    # R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트 객체에 저장.\n",
    "    non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
    "     \n",
    "    # SGD기법으로 P와 Q 매트릭스를 계속 업데이트.\n",
    "    for step in range(steps):\n",
    "        for i, j, r in non_zeros:\n",
    "            # 실제 값과 예측 값의 차이인 오류 값 구함\n",
    "            eij = r - np.dot(P[i, :], Q[j, :].T)\n",
    "            # Regularization을 반영한 SGD 업데이트 공식 적용\n",
    "            P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])\n",
    "            Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])\n",
    "         \n",
    "        rmse = get_rmse(R, P, Q, non_zeros)\n",
    "        if step % 10 == 0:\n",
    "            print(\"### iteration step : \", step,\" rmse : \", np.round(rmse, 7))\n",
    "             \n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#R = pd.DataFrame(s_merge_ratings)\n",
    "s_merge_ratings = pd.DataFrame(s_merge_ratings)\n",
    "#ratings_matrix = R.pivot_table()\n",
    "\n",
    "P, Q = matrix_factorization(s_merge_ratings.values, K=30, steps=41, learning_rate=0.01, r_lambda = 0.01)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pred_matrix = np.dot(P, Q.T) # P @ Q.T 도 가능\n",
    "print('실제 행렬:\\n', s_merge_ratings)\n",
    "print('\\n예측 행렬:\\n', np.round(pred_matrix, 2))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another type SGD code\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class MatrixFactorization():\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
    "        \"\"\"\n",
    "        :param R: rating matrix\n",
    "        :param k: latent parameter\n",
    "        :param learning_rate: alpha on weight update\n",
    "        :param reg_param: beta on weight update\n",
    "        :param epochs: training epochs\n",
    "        :param verbose: print status\n",
    "        \"\"\"\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._learning_rate = learning_rate\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : Update matrix latent weight and bias\n",
    "\n",
    "        참고: self._b에 대한 설명\n",
    "        - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용\n",
    "        - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
    "\n",
    "        :return: training_process\n",
    "        \"\"\"\n",
    "\n",
    "        # init latent features\n",
    "        self._P = np.random.normal(size=(self._num_users, self._k))\n",
    "        self._Q = np.random.normal(size=(self._num_items, self._k))\n",
    "\n",
    "        # init biases\n",
    "        self._b_P = np.zeros(self._num_users)\n",
    "        self._b_Q = np.zeros(self._num_items)\n",
    "        self._b = np.mean(self._R[np.where(self._R != 0)])\n",
    "\n",
    "        # train while epochs\n",
    "        self._training_process = []\n",
    "        for epoch in range(self._epochs):\n",
    "            # rating이 존재하는 index를 기준으로 training\n",
    "            xi, yi = self._R.nonzero()\n",
    "            for i, j in zip(xi, yi):\n",
    "                self.gradient_descent(i, j, self._R[i, j])\n",
    "            cost = self.cost()\n",
    "            self._training_process.append((epoch, cost))\n",
    "\n",
    "            # print status\n",
    "            if self._verbose == True and ((epoch + 1) % 5 == 0):\n",
    "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error\n",
    "        :return: rmse cost\n",
    "        \"\"\"\n",
    "\n",
    "        # xi, yi: R[xi, yi]는 nonzero인 value를 의미한다.\n",
    "        # 참고: http://codepractice.tistory.com/90\n",
    "        xi, yi = self._R.nonzero()\n",
    "        # predicted = self.get_complete_matrix()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - self.get_prediction(x, y), 2)\n",
    "        return np.sqrt(cost/len(xi))\n",
    "\n",
    "\n",
    "    def gradient(self, error, i, j):\n",
    "        \"\"\"\n",
    "        gradient of latent feature for GD\n",
    "\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param j: item index\n",
    "        :return: gradient of latent feature tuple\n",
    "        \"\"\"\n",
    "\n",
    "        dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\n",
    "        dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\n",
    "        return dp, dq\n",
    "\n",
    "\n",
    "    def gradient_descent(self, i, j, rating):\n",
    "        \"\"\"\n",
    "        graident descent function\n",
    "\n",
    "        :param i: user index of matrix\n",
    "        :param j: item index of matrix\n",
    "        :param rating: rating of (i,j)\n",
    "        \"\"\"\n",
    "\n",
    "        # get error\n",
    "        prediction = self.get_prediction(i, j)\n",
    "        error = rating - prediction\n",
    "\n",
    "        # update biases\n",
    "        self._b_P[i] += self._learning_rate * (error - self._reg_param * self._b_P[i])\n",
    "        self._b_Q[j] += self._learning_rate * (error - self._reg_param * self._b_Q[j])\n",
    "\n",
    "        # update latent feature\n",
    "        dp, dq = self.gradient(error, i, j)\n",
    "        self._P[i, :] += self._learning_rate * dp\n",
    "        self._Q[j, :] += self._learning_rate * dq\n",
    "\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        get predicted rating: user_i, item_j\n",
    "        :return: prediction of r_ij\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[i] + self._b_Q[j] + self._P[i, :].dot(self._Q[j, :].T)\n",
    "\n",
    "\n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        computer complete matrix PXQ + P.bias + Q.bias + global bias\n",
    "\n",
    "        - PXQ 행렬에 b_P[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것\n",
    "        - b_Q[np.newaxis:, ]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
    "        - b를 더하는 것은 각 element마다 bias를 더해주는 것\n",
    "\n",
    "        - newaxis: 차원을 추가해줌. 1차원인 Latent들로 2차원의 R에 행/열 단위 연산을 해주기위해 차원을 추가하는 것.\n",
    "\n",
    "        :return: complete matrix R^\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[:, np.newaxis] + self._b_Q[np.newaxis:, ] + self._P.dot(self._Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorizer = MatrixFactorization(s_merge_ratings, k=30, learning_rate=0.05, reg_param=0.02, epochs=1, verbose=True)\n",
    "factorizer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrx = factorizer.get_complete_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrx = pd.DataFrame(mtrx)\n",
    "mtrx = np.round(mtrx, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patterns.index, users.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtrx의 column은 patternId, row는 userId로 바꾸기 \n",
    "mtrx.columns = patterns.index\n",
    "mtrx.index = users.index\n",
    "mtrx.columns.name = \"patternId\"\n",
    "mtrx.index.name = \"userId\"\n",
    "mtrx.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user = \"akinakamori\"\n",
    "new_pattern = 10\n",
    "data = {\n",
    "    new_pattern: '5' # '5' means score\n",
    "}\n",
    "df = pd.DataFrame(data, index=[new_user])\n",
    "appended_mtrx = mtrx.append(df)\n",
    "\n",
    "# 데이터 추가해서 원래 데이터프레임에 저장하기\n",
    "#appended_mtrx = mtrx.append(data_to_insert)\n",
    "appended_mtrx.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtrx.to_csv(\"./sgd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, joblib\n",
    " \n",
    "## Save pickle\n",
    "with open(\"cf.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(factorizer, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = pickle.dumps(factorizer)\n",
    "ft_from_pickle = pickle.loads(saved_model)\n",
    "ft_from_pickle.get_complete_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(factorizer, 'cf_factorization.pkl') \n",
    "ft_from_joblib = joblib.load('cf_factorization.pkl') \n",
    "ft_from_joblib.get_complete_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
