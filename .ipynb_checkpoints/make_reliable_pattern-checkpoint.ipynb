{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>fave_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Crocheturlay</td>\n",
       "      <td>720780</td>\n",
       "      <td>2017/02/19 15:08:49 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cozykrisknits</td>\n",
       "      <td>393166</td>\n",
       "      <td>2014/12/25 14:31:01 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cozykrisknits</td>\n",
       "      <td>447781</td>\n",
       "      <td>2014/12/25 14:29:06 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cozykrisknits</td>\n",
       "      <td>117296</td>\n",
       "      <td>2013/01/07 22:42:44 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cozykrisknits</td>\n",
       "      <td>224811</td>\n",
       "      <td>2013/01/07 22:39:07 -0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756709</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>173758</td>\n",
       "      <td>2013/03/28 16:34:16 -0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756710</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>195006</td>\n",
       "      <td>2013/03/28 16:34:07 -0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756711</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>143595</td>\n",
       "      <td>2013/03/28 16:34:02 -0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756712</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>181436</td>\n",
       "      <td>2013/03/28 16:33:52 -0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756713</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>184008</td>\n",
       "      <td>2013/03/28 16:33:47 -0400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3756714 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id  pattern_id                  fave_date\n",
       "0         Crocheturlay      720780  2017/02/19 15:08:49 -0500\n",
       "1        cozykrisknits      393166  2014/12/25 14:31:01 -0500\n",
       "2        cozykrisknits      447781  2014/12/25 14:29:06 -0500\n",
       "3        cozykrisknits      117296  2013/01/07 22:42:44 -0500\n",
       "4        cozykrisknits      224811  2013/01/07 22:39:07 -0500\n",
       "...                ...         ...                        ...\n",
       "3756709       alchemia      173758  2013/03/28 16:34:16 -0400\n",
       "3756710       alchemia      195006  2013/03/28 16:34:07 -0400\n",
       "3756711       alchemia      143595  2013/03/28 16:34:02 -0400\n",
       "3756712       alchemia      181436  2013/03/28 16:33:52 -0400\n",
       "3756713       alchemia      184008  2013/03/28 16:33:47 -0400\n",
       "\n",
       "[3756714 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"./user_data.csv\", encoding='cp949')\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ratings.groupby('user_id')['user_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern_id\n",
      "10        157\n",
      "13         27\n",
      "16        172\n",
      "17        308\n",
      "20        123\n",
      "         ... \n",
      "774662      1\n",
      "774666      1\n",
      "774667      1\n",
      "774670      1\n",
      "774676      1\n",
      "Name: pattern_id, Length: 410633, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "patterns = ratings.groupby('pattern_id')['pattern_id'].count()\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  count\n",
      "user_id                \n",
      "A-Bear              293\n",
      "A-Jar-Of-Bees        23\n",
      "A-KN                615\n",
      "A-Kelli              65\n",
      "A-Ko-Cloudartowl   3699\n",
      "...                 ...\n",
      "cvilleknits          38\n",
      "cvitt                24\n",
      "cvivianay            44\n",
      "cvjunebug           207\n",
      "cvkasdan             16\n",
      "\n",
      "[11926 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 신뢰할만한 user를 걸러내자.\n",
    "# 어떤 user가 평가한 패턴의 개수가 N개 이상이라면, 이 user는 여러 개의 패턴을 보고 평가한 것으로 볼 수 있다.\n",
    "# 그러므로 이 사용자의 평가는 믿을만하다고 가정한다.\n",
    "N = 10\n",
    "reliable_users = users[users > N]\n",
    "reliable_users = reliable_users.to_frame()\n",
    "# index와, 첫번째 column의 이름이 user_id라 pd.merge 연산이 불가하므로 column name 치환\n",
    "reliable_users.rename(columns={'user_id':'count'}, inplace=True)\n",
    "print(reliable_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 거른 믿을만한 사용자 집단과 rating set의 교집합을 걸러내어,\n",
    "# 믿을만한 사용자 집단이 평가하지 않은 pattern id는 dataset에서 제외한다.\n",
    "merge_ratings = pd.merge(ratings, reliable_users, on=['user_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>fave_date</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crowgirl</td>\n",
       "      <td>390707</td>\n",
       "      <td>2017/03/25 11:08:12 -0400</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowgirl</td>\n",
       "      <td>570883</td>\n",
       "      <td>2016/09/03 19:07:34 -0400</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crowgirl</td>\n",
       "      <td>574591</td>\n",
       "      <td>2016/09/03 19:06:12 -0400</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crowgirl</td>\n",
       "      <td>687166</td>\n",
       "      <td>2016/09/03 19:04:59 -0400</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowgirl</td>\n",
       "      <td>639396</td>\n",
       "      <td>2016/09/03 19:04:00 -0400</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733885</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>173758</td>\n",
       "      <td>2013/03/28 16:34:16 -0400</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733886</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>195006</td>\n",
       "      <td>2013/03/28 16:34:07 -0400</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733887</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>143595</td>\n",
       "      <td>2013/03/28 16:34:02 -0400</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733888</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>181436</td>\n",
       "      <td>2013/03/28 16:33:52 -0400</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733889</th>\n",
       "      <td>alchemia</td>\n",
       "      <td>184008</td>\n",
       "      <td>2013/03/28 16:33:47 -0400</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3733890 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  pattern_id                  fave_date  count\n",
       "0        crowgirl      390707  2017/03/25 11:08:12 -0400     91\n",
       "1        crowgirl      570883  2016/09/03 19:07:34 -0400     91\n",
       "2        crowgirl      574591  2016/09/03 19:06:12 -0400     91\n",
       "3        crowgirl      687166  2016/09/03 19:04:59 -0400     91\n",
       "4        crowgirl      639396  2016/09/03 19:04:00 -0400     91\n",
       "...           ...         ...                        ...    ...\n",
       "3733885  alchemia      173758  2013/03/28 16:34:16 -0400    100\n",
       "3733886  alchemia      195006  2013/03/28 16:34:07 -0400    100\n",
       "3733887  alchemia      143595  2013/03/28 16:34:02 -0400    100\n",
       "3733888  alchemia      181436  2013/03/28 16:33:52 -0400    100\n",
       "3733889  alchemia      184008  2013/03/28 16:33:47 -0400    100\n",
       "\n",
       "[3733890 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "A-Bear               293\n",
      "A-Jar-Of-Bees         23\n",
      "A-KN                 615\n",
      "A-Kelli               65\n",
      "A-Ko-Cloudartowl    3699\n",
      "                    ... \n",
      "cvilleknits           38\n",
      "cvitt                 24\n",
      "cvivianay             44\n",
      "cvjunebug            207\n",
      "cvkasdan              16\n",
      "Name: user_id, Length: 11926, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 교집합 연산이 잘 되었는지 확인을 위한 작업\n",
    "# 교집합 연산 전 reliable users 의 row 길이와, \n",
    "# 현재 merge된 ratings에서 user id끼리 groupby한 연산의 결과가 같으므로, \n",
    "# 이는 옳게 교집합 연산이 되었다\n",
    "users = merge_ratings.groupby('user_id')['user_id'].count()\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern_id\n",
      "10        155\n",
      "13         27\n",
      "16        169\n",
      "17        307\n",
      "20        121\n",
      "         ... \n",
      "774662      1\n",
      "774666      1\n",
      "774667      1\n",
      "774670      1\n",
      "774676      1\n",
      "Name: pattern_id, Length: 409836, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "patterns = merge_ratings.groupby('pattern_id')['pattern_id'].count()\n",
    "print(patterns)\n",
    "# 그러나, 사람마다 취향이 너무 달라서 제외된 패턴임에도 row가 410000개이다. 여전히 너무 많아 MF를 실행할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count\n",
      "pattern_id       \n",
      "10            155\n",
      "13             27\n",
      "16            169\n",
      "17            307\n",
      "20            121\n",
      "...           ...\n",
      "774297         33\n",
      "774351         45\n",
      "774352         13\n",
      "774421         14\n",
      "774443         33\n",
      "\n",
      "[73401 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 이젠 신뢰할만한 pattern을 걸러내자.\n",
    "# 어떤 pattern이 평가된 횟수가 M개 이상이라면, 이 패턴은 많은 사용자에게 평가받았다.\n",
    "# 그러므로 이 패턴은 보편적 취향에 부합하며, 다른 이에게도 추천할만하다.\n",
    "M = 10\n",
    "reliable_patterns = patterns[patterns > M]\n",
    "reliable_patterns = reliable_patterns.to_frame()\n",
    "reliable_patterns.rename(columns={'pattern_id':'count'}, inplace=True)\n",
    "print(reliable_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 거른 믿을만한 사용자 집단과 rating set의 교집합을 걸러내어,\n",
    "# 믿을만한 사용자 집단이 평가하지 않은 pattern id는 dataset에서 제외한다.\n",
    "s_merge_ratings = pd.merge(merge_ratings, reliable_patterns, on=['pattern_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "A-Bear               235\n",
      "A-Jar-Of-Bees         18\n",
      "A-KN                 399\n",
      "A-Kelli               52\n",
      "A-Ko-Cloudartowl    2639\n",
      "                    ... \n",
      "cvilleknits           34\n",
      "cvitt                 17\n",
      "cvivianay             43\n",
      "cvjunebug            120\n",
      "cvkasdan              14\n",
      "Name: user_id, Length: 11922, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# user는 줄지 않았다\n",
    "users = s_merge_ratings.groupby('user_id')['user_id'].count()\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern_id\n",
      "10        155\n",
      "13         27\n",
      "16        169\n",
      "17        307\n",
      "20        121\n",
      "         ... \n",
      "774297     33\n",
      "774351     45\n",
      "774352     13\n",
      "774421     14\n",
      "774443     33\n",
      "Name: pattern_id, Length: 73401, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 교집합 연산이 잘 되었는지 확인을 위한 작업\n",
    "# 교집합 연산 전 reliable patterns 의 row 길이와, \n",
    "# 현재 merge된 ratings에서 pattern id끼리 groupby한 연산의 결과가 같으므로, \n",
    "# 이는 옳게 교집합 연산이 되었다\n",
    "patterns = s_merge_ratings.groupby('pattern_id')['pattern_id'].count()\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [-1, 0, 1]\n",
    "p = np.array([1, 5, 1])\n",
    "m = 5\n",
    "n = 10\n",
    "\n",
    "b_ratings = np.random.choice(responses, size=m*n, p=p / p.sum()).reshape((m, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 1 0 1 1 1]\n",
      " [0 0 0 1 0 0 1 0 1 1]\n",
      " [1 1 0 1 0 0 1 1 0 0]\n",
      " [0 0 1 1 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(b_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization:\n",
    "  def __init__(self, R, k, lr=.0003, l2=.04, seed=777):\n",
    "    self.R = tf.convert_to_tensor(R, dtype=tf.float32)\n",
    "    self.mask = tf.not_equal(self.R, 0)\n",
    "    self.m, self.n = R.shape\n",
    "    self.k = k\n",
    "    self.lr = lr\n",
    "    self.l2 = l2\n",
    "    self.tol = .001\n",
    "    # Initialize trainable weights.\n",
    "    self.weight_init = tf.random_normal_initializer(seed=seed)\n",
    "    self.P = tf.Variable(self.weight_init((self.m, self.k)))\n",
    "    self.Q = tf.Variable(self.weight_init((self.n, self.k)))\n",
    "\n",
    "  def loss(self):\n",
    "    raise NotImplementedError\n",
    "\n",
    "  def grad_update(self):\n",
    "    with tf.GradientTape() as t:\n",
    "      t.watch([self.P, self.Q])\n",
    "      self.current_loss = self.loss()\n",
    "    gP, gQ = t.gradient(self.current_loss, [self.P, self.Q])\n",
    "    self.P.assign_sub(self.lr * gP)\n",
    "    self.Q.assign_sub(self.lr * gQ)\n",
    "\n",
    "  def train(self, n_epoch=5000):\n",
    "    for epoch in range(n_epoch):\n",
    "      self.grad_update()\n",
    "      if self.current_loss < self.tol:\n",
    "        break\n",
    "\n",
    "\n",
    "class RealValueMF(MatrixFactorization):\n",
    "  # The implementation is far from optimized since we don't need the product of entire P'Q.\n",
    "  # We only need scores for non-missing entries.\n",
    "  # The code is hence for educational purpose only.\n",
    "  def loss(self):\n",
    "    \"\"\"Squared error loss.\"\"\"\n",
    "    E = (self.R - tf.matmul(self.P, self.Q, transpose_b=True))**2\n",
    "    l2_norm = tf.reduce_sum(self.P**2) + tf.reduce_sum(self.Q**2)\n",
    "    out = tf.reduce_sum(tf.boolean_mask(E, self.mask)) + self.l2 * l2_norm\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rvmf_model = RealValueMF(ratings, k=3)\\nrvmf_model.train()\\n\\npredictions = tf.matmul(rvmf_model.P, rvmf_model.Q, transpose_b=True).numpy()\\nprint(np.round(predictions * mask, 2))'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''rvmf_model = RealValueMF(ratings, k=3)\n",
    "rvmf_model.train()\n",
    "\n",
    "predictions = tf.matmul(rvmf_model.P, rvmf_model.Q, transpose_b=True).numpy()\n",
    "print(np.round(predictions * mask, 2))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryMF(MatrixFactorization):\n",
    "  def train(self, n_epoch=5000):\n",
    "    # Cast 1/-1 as binary encoding of 0/1.\n",
    "    self.labels = tf.cast(tf.not_equal(tf.boolean_mask(self.R, self.mask), -1), dtype=tf.float32)\n",
    "    for epoch in range(n_epoch):\n",
    "      self.grad_update()\n",
    "\n",
    "  # The implementation is far from optimized since we don't need the product of entire P'Q.\n",
    "  # We only need scores for non-missing entries.\n",
    "  # The code is hence for educational purpose only.\n",
    "  def loss(self):\n",
    "    \"\"\"Cross entropy loss.\"\"\"\n",
    "    logits = tf.boolean_mask(tf.matmul(self.P, self.Q, transpose_b=True), self.mask)\n",
    "    logloss = tf.nn.sigmoid_cross_entropy_with_logits(labels=self.labels, logits=logits)\n",
    "    mlogloss = tf.reduce_mean(logloss)\n",
    "    l2_norm = tf.reduce_sum(self.P**2) + tf.reduce_sum(self.Q**2)\n",
    "    return mlogloss + self.l2 * l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   1.   0.   0.   0.   0.01 0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   1.   0.   0.99 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   1.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   1.   0.   0.   0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# We increase the learning a bit since logloss has a very different scale than squared error.\n",
    "# For the same reason we decrease the L2 coefficient.\n",
    "bmf_model = BinaryMF(b_ratings, k=3, lr=.03, l2=.0001)\n",
    "bmf_model.train()\n",
    "\n",
    "b_predictions = tf.sigmoid(tf.matmul(bmf_model.P, bmf_model.Q, transpose_b=True)).numpy()\n",
    "\n",
    "b_mask = np.zeros_like(b_ratings)\n",
    "b_mask[b_ratings.nonzero()] = 1\n",
    "\n",
    "print(np.round(b_predictions * b_mask, 2)) # Check prediction on training entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.56 1.   0.5  0.98 0.33 0.01 0.51 0.48 0.45 0.48]\n",
      " [0.5  0.55 0.5  0.54 0.48 0.46 0.5  0.5  0.5  0.5 ]\n",
      " [0.52 1.   0.53 0.99 0.06 0.02 0.52 0.49 0.47 0.5 ]\n",
      " [0.52 0.22 0.47 0.16 1.   0.56 0.5  0.52 0.46 0.47]\n",
      " [0.52 0.24 0.47 0.17 1.   0.53 0.5  0.52 0.46 0.47]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(b_predictions, 2))  # Prediction for all entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
